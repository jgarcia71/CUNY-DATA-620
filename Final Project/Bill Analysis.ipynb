{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bill Analysis\n",
    "\n",
    "This script takes the most and least central bills and analyzes their texts and does the same for strongly democratically supported and strongly republican supported bills.\n",
    "\n",
    "We get the data about the most and least central bills as well as the most strongly partisan bills from the jupyter notebook that ranks senators and bills.\n",
    "\n",
    "## Most / Least Central Bills\n",
    "\n",
    "The 20 most central bills from our ranking script, of which we'll use 15 as training and five as test, include sres184, sres292, s1616, sres193, sres254, s1182, sres6, sres173, s1598, s722, sres328, sjres49, sres69, sres211, s274, sres176, s1595, s204, s1094, and s324.\n",
    "\n",
    "The 20 least central bills include s133, s99, s1866, s1609, sres1, sconres24, sres16, sres2, sres57, sres7, sres4, sconres1, sconres2, sres3, s371, s1848, s1631, sres210, sres62, and s1662.\n",
    "\n",
    "\n",
    "## Strongly Partisan Bills\n",
    "\n",
    "The 20 most strongly republican bills include sres1, s723, s724, s590, s1866, s218, s1894, s34, s644, s466, sconres25, s21, s215, s189, s1116, sres298, sres306, s585, sres297, and sres133.\n",
    "\n",
    "The 20 most strongly democratic bills include s729, s617, sres147, sres318, s513, s502, s675, sres275, sjres22, s508, sconres14, s734, s607, s730, sres187, s861, sconres23, s1395, s55, and s225.\n",
    "\n",
    "\n",
    "## Getting Bill Texts\n",
    "\n",
    "Getting full texts of bills can prove challenging.  The ProPublica API does not supply full texts for bills.  We can obtain them by screen-scraping from the Government Publishing Office (GPO).  For example, the page with the text for sres254 is https://www.gpo.gov/fdsys/pkg/BILLS-115sres254ats/html/BILLS-115sres254ats.htm, while senate bill 1616 has several versions, each of which represents a state of the legislation as it goes through consideration.  The final text can be found at https://www.gpo.gov/fdsys/pkg/BILLS-115s1616enr/html/BILLS-115s1616enr.htm .\n",
    "\n",
    "Some investigation and experimentation reveals that the URL we seek can be composed like this:\n",
    "\n",
    "* `https://www.gpo.gov/fdsys/pkg/BILLS-115s1616enr/html/BILLS-115s1616enr.htm` \n",
    "* bill stub (e.g. \"sres254\" or \"s1616\") \n",
    "* code for stage of legislation \n",
    " -  for bills we find: Introduced = \"is\", Referred in House = \"rfh\", Reported = \"rs\", Placed on Calendar = \"pcs\", Engrossed = \"es\", Enrolled = \"enr\"\n",
    " -  for resolutions we find: Introduced = \"is\" , Reported = \"rs\", Agreed to = \"ats\"\n",
    " -  more info about these codes and what they mean can be found at https://www.senate.gov/reference/Printedlegislationkey.htm or  https://www.gpo.gov/help/index.html#about_congressional_bills.htm\n",
    "* `/html/BILLS-115s`\n",
    "* bill stub \n",
    "* code for stage of legislation\n",
    "* `.htm`\n",
    "\n",
    "When we look at the html of a given bill or resolution, we also discover that there's a non-trivial amount of metadata included, such as the legislative sponsors, which we'll want to discard for text analysis (we only want to analyze the contents of the legislation itself).  For example, resolutions have a long separator line followed by the word \"RESOLUTION\".  Everything above that is non-interesting to us (sponsor names and other metadata).  Bills are a little different: they also have a separator line which could be followed by A BILL or AN ACT.\n",
    "\n",
    "So, we have several challenges:\n",
    "\n",
    "* identify the legislative stage of the bill or resolution so we can find the most up-to-date text\n",
    "* construct the URL\n",
    "* obtain, parse, and scrape the html\n",
    "* from the text scraped, obtain just the bill or resolution text (as opposed to the list of sponsors, for example)\n",
    "\n",
    "Let's set up a few variables with data we'll need, if we want to extract these bills in an automated way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_central = ['sres184', 'sres292', 's1616', 'sres193', 'sres254', 's1182', 'sres6', 'sres173', 's1598', 's722', \\\n",
    "                'sres328', 'sjres49', 'sres69', 'sres211', 's274', 'sres176', 's1595', 's204', 's1094', 's324']\n",
    "least_central = ['s133', 's99', 's1866', 's1609', 'sres1', 'sconres24', 'sres16', 'sres2', 'sres57', 'sres7', \\\n",
    "                 'sres4', 'sconres1', 'sconres2', 'sres3', 's371', 's1848', 's1631', 'sres210', 'sres62',  's1662']\n",
    "\n",
    "rep = ['sres1', 's723', 's724', 's590', 's1866', 's218', 's1894', 's34', 's644', 's466', 'sconres25', 's21', 's215',\\\n",
    "       's189', 's1116', 'sres298', 'sres306', 's585', 'sres297', 'sres133']\n",
    "dem = ['s729', 's617', 'sres147', 'sres318', 's513', 's502', 's675', 'sres275', 'sjres22', 's508', 'sconres14', \\\n",
    "       's734', 's607', 's730', 'sres187', 's861', 'sconres23', 's1395', 's55',  's225']\n",
    "\n",
    "bill_status = ['enr', 'es', 'rs', 'rfh', 'is'] # latest to earliest stages\n",
    "resolution_status = ['ats', 'rs', 'is']  # latest to earliest stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we'd like to set up a system that would construct these URL's.  For now we just manually obtained them from the GPO website by choosing the most recent version of each legislation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem_legislation =[\\\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s729rs/html/BILLS-115s729rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s617rs/html/BILLS-115s617rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres147ats/html/BILLS-115sres147ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres318ats/html/BILLS-115sres318ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s513rs/html/BILLS-115s513rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s502rs/html/BILLS-115s502rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s675rs/html/BILLS-115s675rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres275ats/html/BILLS-115sres275ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sjres22es/html/BILLS-115sjres22es.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s508rs/html/BILLS-115s508rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sconres14enr/html/BILLS-115sconres14enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s734rs/html/BILLS-115s734rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s607rs/html/BILLS-115s607rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s730rs/html/BILLS-115s730rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres187ats/html/BILLS-115sres187ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s861pcs/html/BILLS-115s861pcs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sconres23enr/html/BILLS-115sconres23enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1395rs/html/BILLS-115s1395rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s55rs/html/BILLS-115s55rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s225rs/html/BILLS-115s225rs.htm\"]\n",
    "\n",
    "\n",
    "rep_legislation = [\\\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres1ats/html/BILLS-115sres1ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s723rs/html/BILLS-115s723rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s724rs/html/BILLS-115s724rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s590rs/html/BILLS-115s590rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1866enr/html/BILLS-115s1866enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s218rs/html/BILLS-115s218rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1894pcs/html/BILLS-115s1894pcs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s34rs/html/BILLS-115s34rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s644rs/html/BILLS-115s644rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s466rs/html/BILLS-115s466rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sconres25pcs/html/BILLS-115sconres25pcs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s21rs/html/BILLS-115s21rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s215rs/html/BILLS-115s215rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s189rs/html/BILLS-115s189rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1116is/html/BILLS-115s1116is.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres298ats/html/BILLS-115sres298ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres306ats/html/BILLS-115sres306ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s585enr/html/BILLS-115s585enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres297ats/html/BILLS-115sres297ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres133ats/html/BILLS-115sres133ats.htm\"]\n",
    "\n",
    "\n",
    "more_central_legislation = [\\\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres184ats/html/BILLS-115sres184ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres292ats/html/BILLS-115sres292ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1616enr/html/BILLS-115s1616enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres193ats/html/BILLS-115sres193ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres254ats/html/BILLS-115sres254ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1182es/html/BILLS-115s1182es.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres6rs/html/BILLS-115sres6rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres173ats/html/BILLS-115sres173ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1598rs/html/BILLS-115s1598rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s722es/html/BILLS-115s722es.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres328ats/html/BILLS-115sres328ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sjres49enr/html/BILLS-115sjres49enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres69ats/html/BILLS-115sres69ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres211ats/html/BILLS-115sres211ats.htm\",      \n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s274pcs/html/BILLS-115s274pcs.htm\",                    \n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres176ats/html/BILLS-115sres176ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1595rfh/html/BILLS-115s1595rfh.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s204rfh/html/BILLS-115s204rfh.htm\",                  \n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1094enr/html/BILLS-115s1094enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s324es/html/BILLS-115s324es.htm\"]\n",
    "                            \n",
    "                            \n",
    "less_central_legislation = [\\\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s133rs/html/BILLS-115s133rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s99rs/html/BILLS-115s99rs.htm\",                 \n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1866enr/html/BILLS-115s1866enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1609pcs/html/BILLS-115s1609pcs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres1ats/html/BILLS-115sres1ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sconres24enr/html/BILLS-115sconres24enr.htm\",                          \n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres16ats/html/BILLS-115sres16ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres2ats/html/BILLS-115sres2ats.htm\",          \n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres57ats/html/BILLS-115sres57ats.htm\",              \n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres7ats/html/BILLS-115sres7ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres4is/html/BILLS-115sres4is.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sconres1enr/html/BILLS-115sconres1enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sconres2ats/html/BILLS-115sconres2ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres3ats/html/BILLS-115sres3ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s371enr/html/BILLS-115s371enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1848pcs/html/BILLS-115s1848pcs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1631rs/html/BILLS-115s1631rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres210ats/html/BILLS-115sres210ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres62pcs/html/BILLS-115sres62pcs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1662pcs/html/BILLS-115s1662pcs.htm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the texts of the various legislation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def create_corpus(urllist): \n",
    "    legislation_text_list = []\n",
    "    for url in urllist:\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        s = soup.find('pre').find_all(text=True, recursive=False)\n",
    "        clean = str(s).replace('\\\\n','')\n",
    "        split = re.split(\"_{20,}\\s*(AN ACT|RESOLUTION|A BILL)\", clean)\n",
    "        legislation = \" \".join(split[1:])\n",
    "        legislation = legislation.replace('.',' ') # keep.this from being keepthis\n",
    "        legislation = legislation.replace('-',' ')\n",
    "        legislation = legislation.replace('`',' ')\n",
    "        legislation = legislation.replace(';',' ')\n",
    "        legislation = legislation.replace(']',' ')\n",
    "        legislation_text_list.append(legislation)\n",
    "    return(legislation_text_list)\n",
    "\n",
    "more_central_legislation_text = create_corpus(more_central_legislation)\n",
    "less_central_legislation_text = create_corpus(less_central_legislation)\n",
    "rep_legislation_text = create_corpus(rep_legislation)\n",
    "dem_legislation_text = create_corpus(dem_legislation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split our data into training and test data for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "more_train, more_test, less_train, less_test = train_test_split(more_central_legislation_text, \n",
    "                                                                less_central_legislation_text, \n",
    "                                                                test_size=0.25, random_state=42)\n",
    "\n",
    "legislation_train = more_train + less_train\n",
    "legislation_test = more_test + less_test\n",
    "legislation_category_train = [\"more\" for x in more_train] + [\"less\" for x in less_train]\n",
    "legislation_category_test = [\"more\" for x in more_test] + [\"less\" for x in less_test]\n",
    "\n",
    "\n",
    "dem_train, dem_test, rep_train, rep_test = train_test_split(dem_legislation_text, \n",
    "                                                                rep_legislation_text, \n",
    "                                                                test_size=0.25, random_state=42)\n",
    "\n",
    "party_train = dem_train + rep_train\n",
    "party_test = dem_test + rep_test\n",
    "party_category_train = [\"dem\" for x in dem_train] + [\"rep\" for x in rep_train]\n",
    "party_category_test = [\"dem\" for x in dem_test] + [\"rep\" for x in rep_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing and Classifying Corpora: Most vs. Least Central\n",
    "Now that we have access to two sets of data -- most and least central legislation in the 115th Senate -- we can detect if there is any linguistic differences detectable in the text. We're looking, specifically, for distinctive vocabulary. We can do this using TF-IDF (term frequency - inverse document frequency) analysis using ScikitLearn and NLTK.\n",
    "\n",
    "First, we'll check out the overall TF-IDF by category, just to get a feel for the overall tone of the more vs. less central legislation, then we'll do individual TF-IDF by piece of legislation to build a model for machine learning, to see if we can classify text reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Add some known stop words as well as punctuation\n",
    "stop_words = stopwords.words('english') + list(punctuation) + \\\n",
    "            list(['`', 'united', 'states', 'resolution', 'act', 'bill', 'shall', 'section', 'subsection',\n",
    "                 'sec', 'paragraph', 'subparagraph'])\n",
    "def tokenize(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [w.lower() for w in words]\n",
    "    return [w for w in words if w not in stop_words and not w.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "for x in legislation_train:\n",
    "    vocabulary.update(tokenize(x))\n",
    "vocabulary = list(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    " \n",
    "tfidf_category_model = TfidfVectorizer(analyzer='word', stop_words=stop_words, tokenizer=tokenize, vocabulary=vocabulary)\n",
    " \n",
    "# Transform a document into TfIdf coordinates\n",
    "tfidf_category_matrix = tfidf_category_model.fit_transform([' '.join(more_train),\n",
    "                                         ' '.join(less_train)])\n",
    "feature_names = tfidf_category_model.get_feature_names() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from Sparse Matrix to Understandable List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense = tfidf_category_matrix.todense()\n",
    "most = dense[0].tolist()[0]\n",
    "least = dense[1].tolist()[0]\n",
    "\n",
    "most_phrase_scores = [pair for pair in zip(range(0, len(most)), most)]\n",
    "least_phrase_scores = [pair for pair in zip(range(0, len(least)), least)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by Highest TF-IDF and display \n",
    "\n",
    "What are the most distinctive, say, 20 terms in the more central legislation?  To figure this out, we'll want to do tf-idf on the *combination* of all the more central legislation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russian              0.280591045849\n",
      "sanctions            0.235557425096\n",
      "president            0.222881689216\n",
      "federation           0.195968349482\n",
      "person               0.191192349517\n",
      "foreign              0.167953500405\n",
      "respect              0.143658339969\n",
      "committee            0.138376783352\n",
      "described            0.134151538059\n",
      "appropriate          0.121475802179\n",
      "report               0.119363179533\n",
      "ukraine              0.115799479239\n",
      "secretary            0.11196900027\n",
      "may                  0.106687443653\n",
      "government           0.10563113233\n",
      "financial            0.10246219836\n",
      "hizballah            0.102438000866\n",
      "congressional        0.100349575713\n",
      "state                0.0961243304203\n",
      "term                 0.095068019097\n"
     ]
    }
   ],
   "source": [
    "sorted_most_phrase_scores = sorted(most_phrase_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_most_phrase_scores\n",
    "                      if len(feature_names[word_id]) >2][:20]:\n",
    "   print('{0: <20} {1}'.format(phrase, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the least central legislation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available            0.23035534531\n",
      "expenses             0.227300234629\n",
      "provided             0.212024681227\n",
      "department           0.19736014996\n",
      "may                  0.175974375197\n",
      "authorized           0.160087799658\n",
      "committee            0.156421666842\n",
      "exceed               0.142368157711\n",
      "including            0.133813847806\n",
      "funds                0.130147714989\n",
      "expended             0.128925670717\n",
      "law                  0.122815449356\n",
      "public               0.121593405084\n",
      "title                0.114872161587\n",
      "secretary            0.108761940226\n",
      "services             0.103873763137\n",
      "program              0.102040696729\n",
      "activities           0.10020763032\n",
      "necessary            0.0959304753677\n",
      "year                 0.0940974089594\n"
     ]
    }
   ],
   "source": [
    "sorted_least_phrase_scores = sorted(least_phrase_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_least_phrase_scores\n",
    "    if len(feature_names[word_id]) >2][:20]:\n",
    "   print('{0: <20} {1}'.format(phrase, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the \"more central\" legislation has terms that refer to outside countries, like \"sanctions\", \"russian\", \"federation\", \"ukraine\", and \"foreign\", while the \"less central\" legislation has terms that refer to money, like \"expenses\", \"exceed\", \"expended\", and \"funds\".  Will differences like these be enough to distinguish them?  Let's set up some tf-idf analysis and machine learning where we use each document as a data point (instead of just sticking them together for a quick overall look)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer(analyzer='word', stop_words=stop_words, tokenizer=tokenize, vocabulary=vocabulary)\n",
    " \n",
    "# Transform a document into TfIdf coordinates\n",
    "tfidf_matrix = tfidf_model.fit_transform(legislation_train)\n",
    "feature_names = tfidf_model.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(tfidf_matrix, legislation_category_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our accuracy on our training set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: less\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: less\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: less\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n"
     ]
    }
   ],
   "source": [
    "predicted_train = clf.predict(tfidf_model.transform(legislation_train))\n",
    "\n",
    "for i in range(0,len(predicted_train)):\n",
    "    print(\"Actual centrality: \" + legislation_category_train[i] + \",\\tPredicted centrality: \" + predicted_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too shabby!  We only got three wrong out of 30, which is 90% accuracy.  Still, this is almost certainly overfit.  Let's try predicting a few pieces of legislation that weren't used to create the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: less\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: more\n",
      "Actual centrality: less,\tPredicted centrality: more\n",
      "Actual centrality: less,\tPredicted centrality: more\n",
      "Actual centrality: less,\tPredicted centrality: less\n"
     ]
    }
   ],
   "source": [
    "predicted_test = clf.predict(tfidf_model.transform(legislation_test))\n",
    "\n",
    "for i in range(0,len(predicted_test)):\n",
    "    print(\"Actual centrality: \" + legislation_category_test[i] + \",\\tPredicted centrality: \" + predicted_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh, only 6/10 right!  That's around what we'd expect for randomly guessing.  It looks like the text of central and non-central texts is not very predictive when it comes to classifying whether a given bill will be central or non-central.  Legislation text does not work well for classification into \"more\" and \"less\" central.  Could it, however, help classify into \"republican\" or \"democratic\" texts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing and Classifying Corpora: Republican vs Democrat\n",
    "Now that we have access to two sets of data -- most strongly democratic and most strongly republican legislation in the 115th Senate -- we can detect if there is any linguistic differences detectable in the text. We're looking, specifically, for distinctive vocabulary. We can do this using TF-IDF (term frequency - inverse document frequency) analysis using ScikitLearn and NLTK.\n",
    "\n",
    "First, we'll check out the overall TF-IDF by category, just to get a feel for the overall tone of the partisan legislation, then we'll do individual TF-IDF by piece of legislation to build a model for machine learning, to see if we can classify text reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "for x in party_train:\n",
    "    vocabulary.update(tokenize(x))\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "tfidf_category_model = TfidfVectorizer(analyzer='word', stop_words=stop_words, tokenizer=tokenize, vocabulary=vocabulary)\n",
    " \n",
    "# Transform a document into TfIdf coordinates\n",
    "tfidf_category_matrix = tfidf_category_model.fit_transform([' '.join(dem_train),\n",
    "                                         ' '.join(rep_train)])\n",
    "feature_names = tfidf_category_model.get_feature_names() \n",
    "\n",
    "dense = tfidf_category_matrix.todense()\n",
    "dem = dense[0].tolist()[0]\n",
    "rep = dense[1].tolist()[0]\n",
    "\n",
    "dem_scores = [pair for pair in zip(range(0, len(dem)), dem)]\n",
    "rep_scores = [pair for pair in zip(range(0, len(rep)), rep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show democratic distinctive words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "land                 0.321281019517\n",
      "secretary            0.277799377778\n",
      "business             0.210161268406\n",
      "native               0.17634221372\n",
      "eligible             0.169755361966\n",
      "federal              0.157017039614\n",
      "applicant            0.14938471853\n",
      "long                 0.125618967855\n",
      "management           0.125613631691\n",
      "incubator            0.122223860615\n",
      "date                 0.120782338164\n",
      "sound                0.118828753376\n",
      "island               0.118828753376\n",
      "oregon               0.115951044638\n",
      "public               0.101457164058\n",
      "area                 0.09845810994\n",
      "program              0.0966258705314\n",
      "may                  0.0917945770048\n",
      "general              0.0893789302416\n",
      "businesses           0.0893789302416\n"
     ]
    }
   ],
   "source": [
    "sorted_dem_scores = sorted(dem_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_dem_scores\n",
    "                      if len(feature_names[word_id]) >2][:20]:\n",
    "   print('{0: <20} {1}'.format(phrase, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show \"republican\" distinctive words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule                 0.304083428846\n",
      "indian               0.238307212623\n",
      "joint                0.235171591404\n",
      "congress             0.17245916703\n",
      "house                0.163052303373\n",
      "rules                0.141024198885\n",
      "development          0.137967333624\n",
      "national             0.137967333624\n",
      "federal              0.128560469968\n",
      "senate               0.12228922753\n",
      "report               0.119153606311\n",
      "motion               0.110175155379\n",
      "university           0.106611121436\n",
      "may                  0.103475500218\n",
      "date                 0.103475500218\n",
      "described            0.100339878999\n",
      "programs             0.0972042577803\n",
      "whereas              0.0972042577803\n",
      "consideration        0.0925471305182\n",
      "following            0.0909330153429\n"
     ]
    }
   ],
   "source": [
    "sorted_rep_scores = sorted(rep_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_rep_scores\n",
    "                      if len(feature_names[word_id]) >2][:20]:\n",
    "   print('{0: <20} {1}'.format(phrase, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and test a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer(analyzer='word', stop_words=stop_words, tokenizer=tokenize, vocabulary=vocabulary)\n",
    " \n",
    "# Transform a document into TfIdf coordinates\n",
    "tfidf_matrix = tfidf_model.fit_transform(party_train)\n",
    "feature_names = tfidf_model.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(tfidf_matrix, party_category_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's our success rate on our training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: dem\n",
      "Actual centrality: rep,\tPredicted centrality: dem\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: dem\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n"
     ]
    }
   ],
   "source": [
    "predicted_train = clf.predict(tfidf_model.transform(party_train))\n",
    "\n",
    "for i in range(0,len(predicted_train)):\n",
    "    print(\"Actual centrality: \" + party_category_train[i] + \",\\tPredicted centrality: \" + predicted_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, 90% accuracy on training -- but how does it hold up in test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: rep\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: dem,\tPredicted centrality: dem\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: dem\n",
      "Actual centrality: rep,\tPredicted centrality: rep\n",
      "Actual centrality: rep,\tPredicted centrality: dem\n",
      "Actual centrality: rep,\tPredicted centrality: dem\n"
     ]
    }
   ],
   "source": [
    "predicted_test = clf.predict(tfidf_model.transform(party_test))\n",
    "\n",
    "for i in range(0,len(predicted_test)):\n",
    "    print(\"Actual centrality: \" + party_category_test[i] + \",\\tPredicted centrality: \" + predicted_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh, not too fantastic, same as the \"centrality\" model.  Looks like text classification of senate bills either needs more texts to train on, or is simply an unreliable method for classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
