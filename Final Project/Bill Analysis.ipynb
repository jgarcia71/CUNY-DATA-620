{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bill Analysis\n",
    "\n",
    "This script takes the most and least central bills and analyzes their texts.\n",
    "\n",
    "We get the data about the most and least central bills from the jupyter notebook that ranks senators and bills.\n",
    "\n",
    "## Most / Least Central Bills\n",
    "\n",
    "The most central bills from our ranking script include sres254, sres292, sres193, s1616, and sres184, all with vast cosponsorship and a custom centrality measure of 9.737875, as well as slightly less central bills s1182, sres6, sres173, s1598, and s722.\n",
    "\n",
    "The least central bills include sres4, sconres1, sres16, sres7, s1848, s371, sres210, s1631, sres62, and s1662.\n",
    "\n",
    "## Getting Bill Texts\n",
    "\n",
    "Getting full texts of bills can prove challenging.  The ProPublica API does not supply full texts for bills.  We can obtain them by screen-scraping from the Government Publishing Office (GPO).  For example, the page with the text for sres254 is https://www.gpo.gov/fdsys/pkg/BILLS-115sres254ats/html/BILLS-115sres254ats.htm, while senate bill 1616 has several versions, each of which represents a state of the legislation as it goes through consideration.  The final text can be found at https://www.gpo.gov/fdsys/pkg/BILLS-115s1616enr/html/BILLS-115s1616enr.htm .\n",
    "\n",
    "Some investigation and experimentation reveals that the URL we seek can be composed like this:\n",
    "\n",
    "* `https://www.gpo.gov/fdsys/pkg/BILLS-115s1616enr/html/BILLS-115s1616enr.htm` \n",
    "* bill stub (e.g. \"sres254\" or \"s1616\") \n",
    "* code for stage of legislation \n",
    " -  for bills we find: Introduced = \"is\", Referred in House = \"rfh\", Reported = \"rs\", Placed on Calendar = \"pcs\", Engrossed = \"es\", Enrolled = \"enr\"\n",
    " -  for resolutions we find: Introduced = \"is\" , Reported = \"rs\", Agreed to = \"ats\"\n",
    " -  more info about these codes and what they mean can be found at https://www.senate.gov/reference/Printedlegislationkey.htm or  https://www.gpo.gov/help/index.html#about_congressional_bills.htm\n",
    "* `/html/BILLS-115s`\n",
    "* bill stub \n",
    "* code for stage of legislation\n",
    "* `.htm`\n",
    "\n",
    "When we look at the html of a given bill or resolution, we also discover that there's a non-trivial amount of metadata included, such as the legislative sponsors, which we'll want to discard for text analysis (we only want to analyze the contents of the legislation itself).  For example, resolutions have a long separator line followed by the word \"RESOLUTION\".  Everything above that is non-interesting to us (sponsor names and other metadata).  Bills are a little different: they also have a separator line which could be followed by A BILL or AN ACT.\n",
    "\n",
    "So, we have several challenges:\n",
    "\n",
    "* identify the legislative stage of the bill or resolution so we can find the most up-to-date text\n",
    "* construct the URL\n",
    "* obtain, parse, and scrape the html\n",
    "* from the text scraped, obtain just the bill or resolution text (as opposed to the list of sponsors, for example)\n",
    "\n",
    "Let's set up a few variables with data we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_central = ['sres254', 'sres292', 'sres193', 's1616', 'sres184', 's1182', 'sres6', 'sres173', 's1598', 's722']\n",
    "least_central = ['sres4', 'sconres1', 'sres16', 'sres7', 's1848', 's371', 'sres210', 's1631', 'sres62', 's1662']\n",
    "bill_status = ['enr', 'es', 'rs', 'rfh', 'is'] # latest to earliest stages\n",
    "resolution_status = ['ats', 'rs', 'is']  # latest to earliest stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we'd like to set up a system that would construct these URL's.  For now we just manually obtained them from the GPO website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_central_legislation = [\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres254ats/html/BILLS-115sres254ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres292ats/html/BILLS-115sres292ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres193ats/html/BILLS-115sres193ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1616enr/html/BILLS-115s1616enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres184ats/html/BILLS-115sres184ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1182es/html/BILLS-115s1182es.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres6rs/html/BILLS-115sres6rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres173ats/html/BILLS-115sres173ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1598rs/html/BILLS-115s1598rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s722es/html/BILLS-115s722es.htm\"]\n",
    "\n",
    "less_central_legislation = [\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres4is/html/BILLS-115sres4is.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sconres1enr/html/BILLS-115sconres1enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres16ats/html/BILLS-115sres16ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres7ats/html/BILLS-115sres7ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1848pcs/html/BILLS-115s1848pcs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s371enr/html/BILLS-115s371enr.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres210ats/html/BILLS-115sres210ats.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1631rs/html/BILLS-115s1631rs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115sres62pcs/html/BILLS-115sres62pcs.htm\",\n",
    "\"https://www.gpo.gov/fdsys/pkg/BILLS-115s1662pcs/html/BILLS-115s1662pcs.htm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the texts of the various legislation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def create_corpus(urllist): \n",
    "    legislation_text_list = []\n",
    "    for url in urllist:\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        s = soup.find('pre').find_all(text=True, recursive=False)\n",
    "        clean = str(s).replace('\\\\n','')\n",
    "        split = re.split(\"_{20,}\\s*(AN ACT|RESOLUTION|A BILL)\", clean)\n",
    "        legislation = \" \".join(split[1:])\n",
    "        legislation = legislation.replace('.',' ') # keep.this from being keepthis\n",
    "        legislation = legislation.replace('-',' ')\n",
    "        legislation = legislation.replace('`',' ')\n",
    "        legislation = legislation.replace(';',' ')\n",
    "        legislation = legislation.replace(']',' ')\n",
    "        legislation_text_list.append(legislation)\n",
    "    return(legislation_text_list)\n",
    "\n",
    "more_central_legislation_text = create_corpus(more_central_legislation)\n",
    "less_central_legislation_text = create_corpus(less_central_legislation)\n",
    "legislation = more_central_legislation_text + less_central_legislation_text\n",
    "legislation_category = [\"more\" for x in more_central_legislation_text] + [\"less\" for x in less_central_legislation_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Corpora: Most vs. Least Central\n",
    "Now that we have access to two sets of data -- most and least central legislation in the 115th Senate -- we can detect if there is any linguistic differences detectable in the text. We're looking, specifically, for distinctive vocabulary. We can do this using TF-IDF (term frequency - inverse document frequency) analysis using ScikitLearn and NLTK.\n",
    "\n",
    "First, we'll check out the overall TF-IDF by category, just to get a feel for the overall tone of the more vs. less central legislation, then we'll do individual TF-IDF by piece of legislation to build a model for machine learning, to see if we can classify text reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Add some known stop words as well as punctuation\n",
    "stop_words = stopwords.words('english') + list(punctuation) + \\\n",
    "            list(['`', 'united', 'states', 'resolution', 'act', 'bill', 'shall', 'section', 'subsection',\n",
    "                 'sec', 'paragraph', 'subparagraph'])\n",
    "def tokenize(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [w.lower() for w in words]\n",
    "    return [w for w in words if w not in stop_words and not w.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "for x in legislation:\n",
    "    vocabulary.update(tokenize(x))\n",
    "vocabulary = list(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    " \n",
    "tfidf_category_model = TfidfVectorizer(analyzer='word', stop_words=stop_words, tokenizer=tokenize, vocabulary=vocabulary)\n",
    " \n",
    "# Transform a document into TfIdf coordinates\n",
    "tfidf_category_matrix = tfidf_category_model.fit_transform([' '.join(more_central_legislation_text),\n",
    "                                         ' '.join(less_central_legislation_text)])\n",
    "feature_names = tfidf_category_model.get_feature_names() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from Sparse Matrix to Understandable List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense = tfidf_category_matrix.todense()\n",
    "most = dense[0].tolist()[0]\n",
    "least = dense[1].tolist()[0]\n",
    "\n",
    "most_phrase_scores = [pair for pair in zip(range(0, len(most)), most)]\n",
    "least_phrase_scores = [pair for pair in zip(range(0, len(least)), least)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by Highest TF-IDF and display \n",
    "\n",
    "What are the most distinctive, say, 20 terms in the more central legislation?  To figure this out, we'll want to do tf-idf on the *combination* of all the more central legislation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanctions            0.198727800339\n",
      "russian              0.177296370891\n",
      "federation           0.173881047315\n",
      "secretary            0.173399747355\n",
      "president            0.163658188515\n",
      "person               0.157813253211\n",
      "respect              0.139304291414\n",
      "educational          0.137355979646\n",
      "described            0.136381823762\n",
      "program              0.135407667878\n",
      "title                0.134433511994\n",
      "assistance           0.116898706082\n",
      "may                  0.114950394314\n",
      "report               0.110079614894\n",
      "ukraine              0.106793084178\n",
      "foreign              0.10423467959\n",
      "date                 0.103260523706\n",
      "inserting            0.0954672766335\n",
      "committee            0.0915706530975\n",
      "appropriate          0.0896223413294\n"
     ]
    }
   ],
   "source": [
    "sorted_most_phrase_scores = sorted(most_phrase_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_most_phrase_scores\n",
    "                      if len(feature_names[word_id]) >2][:20]:\n",
    "   print('{0: <20} {1}'.format(phrase, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the least central legislation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expenses             0.191430546723\n",
      "department           0.187872358122\n",
      "committee            0.186449082682\n",
      "available            0.172927965999\n",
      "may                  0.170793052838\n",
      "provided             0.170793052838\n",
      "authorized           0.164388313357\n",
      "exceed               0.155848660715\n",
      "public               0.13236461595\n",
      "including            0.128094789629\n",
      "law                  0.127383151908\n",
      "secretary            0.115285310666\n",
      "services             0.112438759785\n",
      "expended             0.110303846625\n",
      "title                0.108880571184\n",
      "funds                0.103187469423\n",
      "period               0.098917643102\n",
      "government           0.0932245413408\n",
      "general              0.0910896281803\n",
      "programs             0.0889547150198\n"
     ]
    }
   ],
   "source": [
    "sorted_least_phrase_scores = sorted(least_phrase_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_least_phrase_scores\n",
    "    if len(feature_names[word_id]) >2][:20]:\n",
    "   print('{0: <20} {1}'.format(phrase, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the \"more central\" legislation has terms that refer to outside countries, like \"sanctions\", \"russian\", \"federation\", \"ukraine\", and \"foreign\", while the \"less central\" legislation has terms that refer to money, like \"expenses\", \"exceed\", \"expended\", and \"funds\".  Will differences like these be enough to distinguish them?  Let's set up some tf-idf analysis and machine learning where we use each document as a data point (instead of just sticking them together for a quick overall look)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer(analyzer='word', stop_words=stop_words, tokenizer=tokenize, vocabulary=vocabulary)\n",
    " \n",
    "# Transform a document into TfIdf coordinates\n",
    "tfidf_matrix = tfidf_model.fit_transform(legislation)\n",
    "feature_names = tfidf_model.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(tfidf_matrix, legislation_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(tfidf_model.transform(legislation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: less\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: more,\tPredicted centrality: more\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n",
      "Actual centrality: less,\tPredicted centrality: less\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(predicted)):\n",
    "    print(\"Actual centrality: \" + legislation_category[i] + \",\\tPredicted centrality: \" + predicted[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too shabby!  We only got one wrong out of 20, which is 95% accuracy.  Still, this is almost certainly overfit.  Let's try predicting a few pieces of legislation that weren't used to create the model.  We'll pick a couple that are nearly as extreme in their centrality as the ones used to generate the model. \n",
    "\n",
    "For example, let's check out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
